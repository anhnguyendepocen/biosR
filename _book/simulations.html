<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Biostatistics in R</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="These are a collection of tutorials that I have found useful in statistical applications.">
  <meta name="generator" content="bookdown 0.0.64 and GitBook 2.6.7">

  <meta property="og:title" content="Biostatistics in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are a collection of tutorials that I have found useful in statistical applications." />
  <meta name="github-repo" content="sahirbhatnagar/biosR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Biostatistics in R" />
  
  <meta name="twitter:description" content="These are a collection of tutorials that I have found useful in statistical applications." />
  

<meta name="author" content="Sahir Rai Bhatnagar">

<meta name="date" content="2016-04-24">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="vectorization-apply-and-for-loops.html">
<link rel="next" href="placeholder.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.6/htmlwidgets.js"></script>
<script src="libs/d3-3.3.8/d3.min.js"></script>
<script src="libs/dagre-0.4.0/dagre-d3.min.js"></script>
<link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet" />
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/chromatography-0.1/chromatography.js"></script>
<script src="libs/DiagrammeR-binding-0.8.2/DiagrammeR.js"></script>
<script src="libs/datatables-binding-0.1/datatables.js"></script>
<script src="libs/datatables-1.10.7/jquery.dataTables.min.js"></script>
<link href="libs/datatables-default-1.10.7/dataTables.extra.css" rel="stylesheet" />
<link href="libs/datatables-default-1.10.7/jquery.dataTables.min.css" rel="stylesheet" />


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Biostatistics in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="vectorization-apply-and-for-loops.html"><a href="vectorization-apply-and-for-loops.html"><i class="fa fa-check"></i><b>2</b> Vectorization, *apply and for loops</a></li>
<li class="chapter" data-level="3" data-path="simulations.html"><a href="simulations.html"><i class="fa fa-check"></i><b>3</b> Simulations</a><ul>
<li class="chapter" data-level="3.1" data-path="simulations.html"><a href="simulations.html#what-is-a-simulation-study"><i class="fa fa-check"></i><b>3.1</b> What is a simulation study?</a></li>
<li class="chapter" data-level="3.2" data-path="simulations.html"><a href="simulations.html#why-conduct-a-simulation-study"><i class="fa fa-check"></i><b>3.2</b> Why conduct a simulation study?</a><ul>
<li class="chapter" data-level="3.2.1" data-path="simulations.html"><a href="simulations.html#understanding-the-behaviour-of-a-statistical-quantity"><i class="fa fa-check"></i><b>3.2.1</b> Understanding the behaviour of a statistical quantity</a></li>
<li class="chapter" data-level="3.2.2" data-path="simulations.html"><a href="simulations.html#model-selection-and-assessment"><i class="fa fa-check"></i><b>3.2.2</b> Model selection and assessment</a></li>
<li class="chapter" data-level="3.2.3" data-path="simulations.html"><a href="simulations.html#calculating-measures-of-uncertainty"><i class="fa fa-check"></i><b>3.2.3</b> Calculating measures of uncertainty</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="placeholder.html"><a href="placeholder.html"><i class="fa fa-check"></i><b>4</b> Placeholder</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Biostatistics in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simulations" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Simulations</h1>
<p>In this chapter you’ll learn how to conduct a simulation study. The word <em>simulation</em> gets thrown around alot as a trivial concept, though I have found that this term is often either misused by epidemiologists or abused by statisticians. A source of this confusion arises from the fact that it is not well defined. This is not by accident. A simulation study has so many moving parts that it would be impossible to characterize in a single word. However, there are some common underlying themes behind simulation studies. For this reason, the main focus here will be on creating a general roadmap for conducting these types of analyses, that can be applied to your specific setting.</p>
<div id="what-is-a-simulation-study" class="section level2">
<h2><span class="header-section-number">3.1</span> What is a simulation study?</h2>
<p>Here are some results from a Google Search:</p>
<ol style="list-style-type: decimal">
<li>A numerical technique for conducting experiments on the computer <span class="citation">(Davidian <a href="placeholder.html#ref-marie">2005</a>)</span></li>
<li>Simulations provide a powerful technique for answering a broad set of methodological and theoretical questions and provide a flexible framework to answer specific questions relevant to one’s own research<span class="citation">(Hallgren <a href="placeholder.html#ref-hallgren2013conducting">2013</a>)</span></li>
</ol>
<p>I prefer the second definition because it speaks to the generality of simulations. I see simulations in the following way<a href="placeholder.html#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>:</p>
<p><div id="htmlwidget-8266" style="width:672px;height:200px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-8266">{"x":{"diagram":"\ngraph LR\nA((Input))-->B{Procedure}\nB-->C[Output]\n"},"evals":[],"jsHooks":[]}</script></p>
<p>There are three crucial components to any simulation study:</p>
<ol style="list-style-type: decimal">
<li><strong>Procedure</strong> - something that doesn’t change throughout the simulation study</li>
<li><strong>Input</strong>: <em>several</em> values of the same quantity that are passed to the procedure.</li>
<li><strong>Output</strong>: result from the procedure being applied to the inputs. Should be equal in length to the number of outputs. The following toy example illustrates this point:</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_sample_median &lt;-<span class="st"> </span>function(true_mean) {
  x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">20</span>, <span class="dt">mean =</span> true_mean, <span class="dt">sd =</span> <span class="dv">1</span>)
  <span class="kw">median</span>(x)
}

(means &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>))</code></pre></div>
<pre><code>## [1] 1 2 3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(sample_medians &lt;-<span class="st"> </span><span class="kw">sapply</span>(means, f_sample_median))</code></pre></div>
<pre><code>## [1] 1.119985 1.860057 2.964291</code></pre>
<p>So here, <code>f_sample_median</code> is the procedure that generates 20 random numbers from a normal distribution with standard deviation 1 and a user specified mean, and outputs the sample median. <code>means</code> is the input vector of user specified means, and <code>sample_medians</code> is the output:</p>
<p><div id="htmlwidget-6479" style="width:672px;height:300px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-6479">{"x":{"diagram":"\ngraph LR\nA((1))-->B{f_sample_median}\nD((2))-->B\nE((3))-->B\nB-->C[1.12]\nB-->F[1.86]\nB-->G[2.96]\n"},"evals":[],"jsHooks":[]}</script></p>
<p>Using this very general definition of the word <em>simulation</em>, I see the following analysis techinques as a type of simulation.</p>
<p><div id="htmlwidget-3198" style="width:672px;height:200px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-3198">{"x":{"diagram":"\ngraph TB\nsq[Simulation] --> ci[Bootstrap]\nsq --> A[Cross Validation]\nsq --> B[Sensitivity Analysis]\nsq --> C[Permutations]\nclassDef green fill:#9f6,stroke:#333,stroke-width:2px;\nclassDef orange fill:#f96,stroke:#333,stroke-width:4px;\nclass sq green\n"},"evals":[],"jsHooks":[]}</script></p>
<p>Boostrap, Cross Validation, Sensitivity analysis and Permutations are all similar in that they have multiple inputs with an equal number of outputs, with a fixed procedure. What differentiates them is the context in which they can be applied. The technique you choose depends entirely on the question you’re trying to answer.</p>
</div>
<div id="why-conduct-a-simulation-study" class="section level2">
<h2><span class="header-section-number">3.2</span> Why conduct a simulation study?</h2>
<p>The most common applications of simulation studies are the following</p>
<div id="understanding-the-behaviour-of-a-statistical-quantity" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Understanding the behaviour of a statistical quantity</h3>
<div id="example-1-the-central-limit-theorem" class="section level4">
<h4><span class="header-section-number">3.2.1.1</span> Example 1: The Central Limit Theorem</h4>
<p>The <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">Central Limit Theorem</a> is one of the most famous theorems in statistics. This theorem basically states that the sum or mean of independent random variables (with finite mean and variance) will converge to a normal distribution, regardless of the distribution of the random variables. The following figure clearly illustrates this point <span class="citation">(Joseph <a href="placeholder.html#ref-joseph">2010</a>)</span></p>
<p><img src="images/clt.png" alt="" /><!-- --></p>
<p>In this example, the statistical quantity of interest is the sum of the random variables. We want to verify that the sum of the time it takes to get to Purvis hall follows a normal distribution as the number of observations approaches infinity. Of course the CLT can be proven mathematically, but we can also simulate random numbers from different distributions in <code>R</code> to numerically verify this result. The simulation framework can be seen as follows:</p>
<p><div id="htmlwidget-3077" style="width:672px;height:480px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-3077">{"x":{"diagram":"\ngraph LR\nA((Sample size n = 20))-->B{Generate n random numbers from<br>different distributions}\nD((Sample size n = 100))-->B\nE((Sample size n = 1000))-->B\nB-->C[Mean and variance of<br>sum based on n = 20]\nB-->F[Mean and variance of<br>sum based on n = 100]\nB-->G[Mean and variance of<br>sum based on n = 1000]\n"},"evals":[],"jsHooks":[]}</script></p>
<p>Here we show a single run of the simulation with <span class="math inline">\(n = 10,000\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># number of observations to generate from each distribution</span>
n &lt;-<span class="st"> </span><span class="fl">1e4</span>

<span class="co"># true parameters of each distribution</span>
mean.walk &lt;-<span class="st"> </span><span class="dv">4</span> ; var.walk &lt;-<span class="st"> </span><span class="dv">1</span>
mean.bus &lt;-<span class="st"> </span>(<span class="dv">4+16</span>)/<span class="dv">2</span> ; var.bus &lt;-<span class="st"> </span>(<span class="dv">16-4</span>)^<span class="dv">2</span>/<span class="dv">12</span>
mean.ride &lt;-<span class="st"> </span><span class="dv">8</span> ; var.ride &lt;-<span class="st"> </span><span class="dv">8</span> 
mean.climb &lt;-<span class="st"> </span><span class="dv">6</span>*<span class="fl">0.5</span> ; var.climb &lt;-<span class="st"> </span><span class="dv">6</span>*<span class="fl">0.5</span>^<span class="dv">2</span>
mean.fall &lt;-<span class="st"> </span><span class="dv">1</span>/<span class="dv">4</span> ; var.fall &lt;-<span class="st"> </span><span class="dv">1</span>/<span class="dv">4</span>^<span class="dv">2</span>

<span class="co"># generate random samples from each distribution</span>
walk &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, mean.walk, var.walk)
bus &lt;-<span class="st"> </span><span class="kw">runif</span>(n, <span class="dv">4</span>, <span class="dv">16</span>)
ride &lt;-<span class="st"> </span><span class="kw">rpois</span>(n, mean.ride)
climb &lt;-<span class="st"> </span><span class="kw">rgamma</span>(n, <span class="dt">shape =</span> <span class="dv">6</span>, <span class="dt">scale =</span> <span class="fl">0.5</span>)
fall &lt;-<span class="st"> </span><span class="kw">rexp</span>(n, <span class="dt">rate =</span> <span class="dv">1</span>/mean.fall)

<span class="co"># true mean and variance of sum</span>
mean.sum &lt;-<span class="st"> </span>mean.walk+mean.bus+mean.ride+mean.climb+mean.fall
var.sum &lt;-<span class="st"> </span>var.walk+var.bus+var.ride+var.climb+var.fall

<span class="co"># create a data frame of the data and calculate the sum for each sample</span>
DT &lt;-<span class="st"> </span><span class="kw">data.frame</span>(walk, bus, ride, climb, fall)
DT$sum &lt;-<span class="st"> </span><span class="kw">apply</span>(DT,<span class="dv">1</span>,sum)

<span class="co"># plot each histogram and superimpose theoretical </span>
<span class="co"># distribution to empirical one</span>
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))
<span class="kw">hist</span>(walk, <span class="dt">main=</span><span class="st">&quot;Normal(mean=4,sd=1)&quot;</span>, <span class="dt">freq=</span><span class="ot">FALSE</span>)
<span class="kw">hist</span>(bus, <span class="dt">main=</span><span class="st">&quot;Uniform(a=4,b=16)&quot;</span>, <span class="dt">freq=</span><span class="ot">FALSE</span>)
<span class="kw">hist</span>(ride, <span class="dt">main=</span><span class="st">&quot;Poisson(lambda=8)&quot;</span>, <span class="dt">freq=</span><span class="ot">FALSE</span>)
<span class="kw">hist</span>(climb, <span class="dt">main=</span><span class="st">&quot;Gamma(shape=6, scale=0.5)&quot;</span>, <span class="dt">freq=</span><span class="ot">FALSE</span>)
<span class="kw">hist</span>(fall, <span class="dt">main=</span><span class="st">&quot;Exponential(rate=4)&quot;</span>, <span class="dt">freq=</span><span class="ot">FALSE</span>)
<span class="kw">hist</span>(DT$sum, <span class="dt">xlab=</span><span class="st">&#39;Total time&#39;</span>, <span class="dt">main=</span><span class="kw">paste</span>(<span class="st">&quot;Distribution of Sum, n = &quot;</span>,n), <span class="dt">freq=</span><span class="ot">FALSE</span>)
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x,<span class="dt">mean=</span>mean.sum,<span class="dt">sd=</span><span class="kw">sqrt</span>(var.sum)),<span class="dv">0</span>,<span class="dv">50</span>,<span class="dt">add=</span><span class="ot">TRUE</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-7-1.png" alt="" /><!-- --></p>
</div>
<div id="example-2-power-calculation" class="section level4">
<h4><span class="header-section-number">3.2.1.2</span> Example 2: Power Calculation</h4>
<p>When performing <a href="https://en.wikipedia.org/wiki/Student%27s_t-test">Student’s t-test</a> to compare difference in means between two groups, it is a useful exercise to determine the effect of unequal sample sizes in the comparison group on <strong>power</strong>. Large imbalances generally will not have adequate statistical power to detect even large effect sizes associated with a factor, leading to a high Type II error rate. To jusity this reasoning I performed a power analysis for different group sizes. A power curve typically has power (the probability of rejecting the null hypothesis when the alternative hypothesis is true) on the y-axis, and a measure of association (or effect size) on the x-axis. For a given sample size of both groups, we can calculate a power curve by varying the true effect size. The simulation framework can be seen as follows:</p>
<p><div id="htmlwidget-3769" style="width:672px;height:480px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-3769">{"x":{"diagram":"\ngraph LR\nA((Effect Size 0.1))-->B{Procedure to calculate<br>power for t-test}\nD((Effect Size 0.5))-->B\nE((Effect Size 1))-->B\nB-->C[Power for effect size of 0.1]\nB-->F[Power for effect size of 0.5]\nB-->G[Power for effect size of 1]\n"},"evals":[],"jsHooks":[]}</script></p>
<p>I considered the following group sizes:</p>
<ol style="list-style-type: decimal">
<li>n1 = 28, n2 = 1406: n1 represents 2% of the entire sample size of 1434</li>
<li>n1 = 144, n2 = 1290: n1 represents 10% of the entire sample size of 1434</li>
<li>n1 = 287, n2 = 1147: n1 represents 20% of the entire sample size of 1434</li>
<li>n1 = 430, n2 = 1004: n1 represents 30% of the entire sample size of 1434</li>
<li>n1 = 574, n2 = 860: n1 represents 40% of the entire sample size of 1434</li>
<li>n1 = 717, n2 = 717: equal size groups (this is optimal because it leads to the highest power for a given effect size)</li>
</ol>
<p>In the figure below we plot the power curves for the <span class="math inline">\(t\)</span>-test, as a function of the effect size, assuming a Type I error rate of 5%.</p>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-10-1.png" alt="" /><!-- --></p>
<p>Here is the code used to produce the above plot</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pwr) <span class="co"># for power calcs</span>
<span class="kw">library</span>(dplyr) <span class="co"># for data manipulation</span>
<span class="kw">library</span>(tidyr) <span class="co"># for data manipulation</span>
<span class="kw">library</span>(ggplot2) <span class="co"># for plotting power curves</span>

<span class="co"># Generate power calculations</span>
ptab &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="ot">NULL</span>, <span class="ot">NULL</span>)       

for (i in <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">length.out =</span> <span class="dv">200</span>)){
  pwrt1 &lt;-<span class="st"> </span><span class="kw">pwr.t2n.test</span>(<span class="dt">n1 =</span> <span class="dv">28</span>, <span class="dt">n2 =</span> <span class="dv">1406</span>, 
                        <span class="dt">sig.level =</span> <span class="fl">0.05</span>, <span class="dt">power =</span> <span class="ot">NULL</span>, 
                        <span class="dt">d =</span> i, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>)
  pwrt2 &lt;-<span class="st"> </span><span class="kw">pwr.t2n.test</span>(<span class="dt">n1 =</span> <span class="dv">144</span>, <span class="dt">n2 =</span> <span class="dv">1290</span>, 
                        <span class="dt">sig.level =</span> <span class="fl">0.05</span>, <span class="dt">power =</span> <span class="ot">NULL</span>, 
                        <span class="dt">d =</span> i, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>)
  pwrt3 &lt;-<span class="st"> </span><span class="kw">pwr.t2n.test</span>(<span class="dt">n1 =</span> <span class="dv">287</span>, <span class="dt">n2 =</span> <span class="dv">1147</span>, 
                        <span class="dt">sig.level =</span> <span class="fl">0.05</span>, <span class="dt">power =</span> <span class="ot">NULL</span>, 
                        <span class="dt">d =</span> i, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>)
  pwrt4 &lt;-<span class="st"> </span><span class="kw">pwr.t2n.test</span>(<span class="dt">n1 =</span> <span class="dv">430</span>, <span class="dt">n2 =</span> <span class="dv">1004</span>, 
                        <span class="dt">sig.level =</span> <span class="fl">0.05</span>, <span class="dt">power =</span> <span class="ot">NULL</span>, 
                        <span class="dt">d =</span> i, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>)
  pwrt5 &lt;-<span class="st"> </span><span class="kw">pwr.t2n.test</span>(<span class="dt">n1 =</span> <span class="dv">574</span>, <span class="dt">n2 =</span> <span class="dv">860</span>, 
                        <span class="dt">sig.level =</span> <span class="fl">0.05</span>, <span class="dt">power =</span> <span class="ot">NULL</span>, 
                        <span class="dt">d =</span> i, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>)
  pwrt6 &lt;-<span class="st"> </span><span class="kw">pwr.t2n.test</span>(<span class="dt">n1 =</span> <span class="dv">717</span>, <span class="dt">n2 =</span> <span class="dv">717</span>, 
                        <span class="dt">sig.level =</span> <span class="fl">0.05</span>, <span class="dt">power =</span> <span class="ot">NULL</span>, 
                        <span class="dt">d =</span> i, <span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>)
  ptab &lt;-<span class="st"> </span><span class="kw">rbind</span>(ptab, <span class="kw">cbind</span>(pwrt1$d, pwrt1$power,
                            pwrt2$d, pwrt2$power,
                            pwrt3$d, pwrt3$power,
                            pwrt4$d, pwrt4$power,
                            pwrt5$d, pwrt5$power,
                            pwrt6$d, pwrt6$power))
}

ptab &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">seq_len</span>(<span class="kw">nrow</span>(ptab)), ptab)

<span class="kw">colnames</span>(ptab) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;id&quot;</span>,<span class="st">&quot;n1=28, n2=1406.effect size&quot;</span>,<span class="st">&quot;n1=28, n2=1406.power&quot;</span>,
                    <span class="st">&quot;n1=144, n2=1290.effect size&quot;</span>,<span class="st">&quot;n1=144, n2=1290.power&quot;</span>,
                    <span class="st">&quot;n1=287, n2=1147.effect size&quot;</span>,<span class="st">&quot;n1=287, n2=1147.power&quot;</span>,
                    <span class="st">&quot;n1=430, n2=1004.effect size&quot;</span>,<span class="st">&quot;n1=430, n2=1004.power&quot;</span>,
                    <span class="st">&quot;n1=574, n2=860.effect size&quot;</span>,<span class="st">&quot;n1=574, n2=860.power&quot;</span>,
                    <span class="st">&quot;n1=717, n2=717.effect size&quot;</span>,<span class="st">&quot;n1=717, n2=717.power&quot;</span>)

<span class="co"># get data into right format for ggplot2</span>
temp &lt;-<span class="st"> </span>ptab %&gt;%
<span class="st">  </span><span class="kw">as.data.frame</span>() %&gt;%
<span class="st">  </span><span class="kw">gather</span>(<span class="dt">key =</span> name, <span class="dt">value =</span> val, <span class="dv">2</span>:<span class="dv">13</span>) %&gt;%
<span class="st">  </span><span class="kw">separate</span>(<span class="dt">col =</span> name, <span class="dt">into =</span> <span class="kw">c</span>(<span class="st">&quot;group&quot;</span>, <span class="st">&quot;var&quot;</span>), <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\\</span><span class="st">.&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key =</span> var, <span class="dt">value =</span> val)

<span class="co"># factor group</span>
temp$group &lt;-<span class="st"> </span><span class="kw">factor</span>(temp$group, 
                <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;n1=28, n2=1406&quot;</span>, <span class="st">&quot;n1=144, n2=1290&quot;</span>, 
                <span class="st">&quot;n1=287, n2=1147&quot;</span>, <span class="st">&quot;n1=430, n2=1004&quot;</span>,
                <span class="st">&quot;n1=574, n2=860&quot;</span>, <span class="st">&quot;n1=717, n2=717&quot;</span>))


<span class="co"># plot</span>
p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(temp, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="st">`</span><span class="dt">effect size</span><span class="st">`</span>, <span class="dt">y =</span> power, <span class="dt">color =</span> group))
p +<span class="st"> </span>
<span class="kw">geom_line</span>(<span class="dt">size=</span><span class="dv">2</span>) +<span class="st"> </span>
<span class="kw">theme_bw</span>() +<span class="st"> </span>
<span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>, 
      <span class="dt">axis.text=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">14</span>), 
      <span class="dt">axis.title=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">14</span>), 
      <span class="dt">legend.text=</span><span class="kw">element_text</span>(<span class="dt">size=</span><span class="dv">14</span>))</code></pre></div>
</div>
</div>
<div id="model-selection-and-assessment" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Model selection and assessment</h3>
<p>Model selection refers to</p>
<blockquote>
<p>Estimating the performance of different models in order to choose the best one <span class="citation">(Hastie, Tibshirani, and Friedman <a href="placeholder.html#ref-esl">2009</a>)</span></p>
</blockquote>
<p>Model assessment refers to</p>
<blockquote>
<p>Estimating the prediction error on new data, given that a model has been selected</p>
</blockquote>
<p>In real data analysis problems we often have many models to choose from, for example, different combinations of covariates result in different models. The question is how can we can select the model that best fits the data and generalizes to other datasets? Information criteria such as the AIC, BIC and QIC can be used in different settings, however there are some known pitfalls to these (see for example <span class="citation">Y. Wang et al. (<a href="placeholder.html#ref-wang2015perils">2015</a>)</span>).</p>
Here is an example of model selection in the penalized regression setting. We consider a regression model for an outcome variable <span class="math inline">\(Y=(y_1, \ldots, y_n)\)</span> which follows an exponential family. Let <span class="math inline">\(\boldsymbol{X} = (X_{1}, \ldots, X_{p})\)</span> be a matrix of covariates, where <span class="math inline">\(p &gt;&gt; n\)</span>. Consider the regression model with main effects:
\begin{align}
g(\boldsymbol{\mu})  = &amp; \beta_0  + \beta_1 X_{1} + \cdots + \beta_p X_p  \label{eq:linpred1}
\end{align}
where <span class="math inline">\(g(\cdot)\)</span> is a known link function and <span class="math inline">\(\boldsymbol{\mu} = \mathsf{E}\left[Y|\boldsymbol{X}, \boldsymbol{\beta} \right]\)</span>. Our goal is to estimate the parameters <span class="math inline">\(\boldsymbol{\beta} = \left(\beta_1, \beta_2, \ldots, \beta_p\right) \in \mathbb{R}^{p+1}\)</span>. Due to the large number of parameters to estimate with respect to the number of observations, one commonly-used approach is to shrink the regression coefficients by placing a constraint on the values of <span class="math inline">\(\boldsymbol{\beta}\)</span>. For example, the LASSO <span class="citation">(R. Tibshirani <a href="placeholder.html#ref-tibshirani1996regression">1996</a>)</span> penalizes the squared loss of the data with the  of the regression coefficients resulting in a method that performs both model selection and estimation:
\begin{equation}
argmin_{\beta_0, \boldsymbol{\beta} } \,\,\, \frac{1}{2} \left\Vert Y - g(\boldsymbol{\mu}) \right\Vert ^2 + \lambda  \left\Vert \boldsymbol{\beta} \right\Vert_1  \label{eq:lassolikelihood}
\end{equation}
<p>where <span class="math inline">\(\left\Vert Y - g(\boldsymbol{\mu})\right\Vert^2 = \sum_i (y_i - g(\mu_i))^2\)</span>, <span class="math inline">\(\left\Vert \boldsymbol{\beta}\right\Vert_1 = \sum_j | \beta_j |\)</span> and <span class="math inline">\(\lambda \geq 0\)</span> is a data driven tuning parameter that can set some of the coefficients to zero when sufficiently large.</p>
<p>It should be noted here that different tuning parameters will lead to different models. So the question here is how to choose the optimal <span class="math inline">\(\lambda\)</span>. A very common techinque is to use cross-validation <span class="citation">(Hastie, Tibshirani, and Friedman <a href="placeholder.html#ref-esl">2009</a>)</span>:</p>
<p><img src="images/cv.png" alt="" /><!-- --></p>
<p>The data is split into <span class="math inline">\(K = 5\)</span> (or 10) roughly equal sized parts. The model is fit on all the data except the Kth part, and the prediction error of the fitted model is calculated on the Kth part. This is repeated K times, and the error from each fold is averaged. The simulation framework can be seen as follows:</p>
<p><div id="htmlwidget-4492" style="width:672px;height:480px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-4492">{"x":{"diagram":"\ngraph LR\nA((Fold 1))-->B{Fit LASSO Model<br>on remaining folds}\nD((Fold 2))-->B\nE((Fold 3))-->B\nF((Fold 4))-->B\nG((Fold 5))-->B\nB-->C[Prediction error<br>on left-out fold]\nB-->H[Prediction error<br>on left-out fold]\nB-->I[Prediction error<br>on left-out fold]\nB-->J[Prediction error<br>on left-out fold]\nB-->K[Prediction error<br>on left-out fold]\n"},"evals":[],"jsHooks":[]}</script></p>
<p>Note this is for a single tuning parameter. We would repeat the above steps for a range of tuning parameters. This technique for choosing the tuning parameter in Equation \ref{eq:lassolikelihood} is implemented in the <code>glmnet</code> package <span class="citation">(J. Friedman et al. <a href="placeholder.html#ref-R-glmnet">2016</a>)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(glmnet)
<span class="kw">set.seed</span>(<span class="dv">12345</span>)

<span class="co"># number of subjects</span>
n &lt;-<span class="st"> </span><span class="dv">100</span>

<span class="co"># number of covariates</span>
p &lt;-<span class="st"> </span><span class="dv">1000</span>

<span class="co"># number of true non-zero coefficients</span>
nzc &lt;-<span class="st"> </span><span class="dv">25</span>

<span class="co"># covariates</span>
x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n*p),n,p)

<span class="co"># true beta coefficients</span>
beta &lt;-<span class="st"> </span><span class="kw">rnorm</span>(nzc)

<span class="co"># generate response. only the first nzc are associated with y</span>
y &lt;-<span class="st"> </span>x[,<span class="kw">seq</span>(nzc)] %*%<span class="st"> </span>beta +<span class="st"> </span><span class="kw">rnorm</span>(n)*<span class="dv">5</span>

<span class="co"># perform cross-validation</span>
cvobj &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(x,y)

<span class="co"># plot cross validation curve</span>
<span class="kw">plot</span>(cvobj)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-14-1.png" alt="" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># final selected model based on CV-selected lambda</span>
coefobj &lt;-<span class="st"> </span><span class="kw">coef</span>(cvobj, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>)

<span class="co"># non-zero elements of selected model and their effect estimate</span>
coefobj[glmnet:::<span class="kw">nonzeroCoef</span>(coefobj),,drop =<span class="st"> </span>F]</code></pre></div>
<pre><code>## 31 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                       1
## (Intercept)  0.33746196
## V11         -0.88033906
## V16         -1.91994340
## V17          1.11662951
## V19          0.58131900
## V39          0.11067061
## V49         -0.10673164
## V54         -0.09201722
## V143        -0.17211302
## V204         0.08452316
## V234         0.16363999
## V271         0.09728157
## V275         0.12263144
## V312        -0.08838243
## V338        -0.34694844
## V339         0.17656390
## V388        -0.00927594
## V423         0.24150449
## V429        -0.03885577
## V493        -0.10920236
## V541         0.37624248
## V548         1.07802523
## V618         0.12164737
## V660        -0.15121156
## V702        -0.19438313
## V790         0.43667721
## V867         0.25084326
## V960         0.23430632
## V981        -0.31318982
## V984         0.51441461
## V985         0.30346286</code></pre>
<p>While we have shown an example of model selection, cross validation can also be used to assess the chosen model but this should be done on an <strong>independent</strong> data set, i.e., one that was not used to train and select the model.</p>
</div>
<div id="calculating-measures-of-uncertainty" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Calculating measures of uncertainty</h3>
<p>The Bootstrap <span class="citation">(Efron and Tibshirani <a href="placeholder.html#ref-efron1994introduction">1994</a>)</span> is a widely used procedure to calculate measures of uncertainty (e.g. confidence intervals, standard errors of paramters). Its popularity is due to its relative simplicity. Furthermore, the data analyst often has no choice but to bootstrap because no closed form mathematical solution exists. The main idea is summarised in the following diagram:</p>
<p><img src="images/sd.jpg" alt="" /><!-- --></p>
<div id="example-1-non-parametric-bootstrap-for-confidence-intervals-of-the-mean" class="section level4">
<h4><span class="header-section-number">3.2.3.1</span> Example 1: Non-parametric Bootstrap for Confidence Intervals of the mean<a href="placeholder.html#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></h4>
<p>The following data are the survival times for mice in a randomized experiment comparing a treated group with a control group.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># control group</span>
(mouse.c &lt;-<span class="st"> </span><span class="kw">scan</span>(<span class="st">&quot;http://www.rohan.sdsu.edu/~babailey/stat672/mouse.c.data&quot;</span>))</code></pre></div>
<pre><code>## [1]  52 104 146  10  50  31  40  27  46</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># treatment group</span>
(mouse.t &lt;-<span class="st"> </span><span class="kw">scan</span>(<span class="st">&quot;http://www.rohan.sdsu.edu/~babailey/stat672/mouse.t.data&quot;</span>))</code></pre></div>
<pre><code>## [1]  94 197  16  38  99 141  23</code></pre>
<p>We are interested in bootstrap confidence intervals for the mean survival time in the control group:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># number of mice in control group</span>
n.c &lt;-<span class="st"> </span><span class="kw">length</span>(mouse.c)

<span class="co"># point estimates of mean and standard error of survival time</span>
<span class="kw">mean</span>(mouse.c)</code></pre></div>
<pre><code>## [1] 56.22222</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># recall that standard error of the mean is sigma/sqrt{n}</span>
<span class="co"># if the presumption of normality is made than this is the </span>
<span class="co"># plug-in estimate of the standard error</span>
<span class="kw">sd</span>(mouse.c)*<span class="kw">sqrt</span>((n.c<span class="dv">-1</span>)/n.c^<span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 13.33035</code></pre>
<p>We take advantage of thee very flexible <code>boot</code> package <span class="citation">(Canty and Ripley <a href="placeholder.html#ref-R-boot">2015</a>)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(boot)

<span class="co"># define a function where the first argument is the data</span>
<span class="co"># and the second argument will take a vector of indices used to subset the data</span>
meancalc &lt;-<span class="st"> </span>function(x,i) {
  
    <span class="co"># always subset the data first</span>
     d &lt;-<span class="st"> </span>x[i]
     m &lt;-<span class="st"> </span><span class="kw">mean</span>(d)
     n &lt;-<span class="st"> </span><span class="kw">length</span>(i)
     v &lt;-<span class="st"> </span>(n<span class="dv">-1</span>)*<span class="kw">var</span>(d)/n^<span class="dv">2</span>
     
     <span class="co"># bootstrap variances needed for studentized intervals</span>
     <span class="kw">return</span>(<span class="kw">c</span>(m, v))
}

<span class="co"># run the boot function for B=10,000 bootstrap samples</span>
<span class="co"># the bootstrap statistics returns the bias for the sample mean (t1)</span>
<span class="co"># and sample variance </span>
(bmean &lt;-<span class="st"> </span><span class="kw">boot</span>(mouse.c, meancalc, <span class="dt">R =</span> <span class="fl">1e4</span>))</code></pre></div>
<pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = mouse.c, statistic = meancalc, R = 10000)
## 
## 
## Bootstrap Statistics :
##      original      bias    std. error
## t1*  56.22222  -0.1363111    13.37626
## t2* 177.69822 -19.7009962    83.86027</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># calculate different types of confidence intervals</span>
mouse.ci &lt;-<span class="st"> </span><span class="kw">boot.ci</span>(bmean)

<span class="co"># histogram of bootstrap replicates and confidence intervals</span>
<span class="kw">hist</span>(bmean$t[,<span class="dv">1</span>], <span class="dt">xlab =</span> <span class="kw">expression</span>(theta), <span class="dt">col=</span><span class="st">&#39;gray&#39;</span>, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">150</span>),
     <span class="dt">main =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Bootstrap resamples of &#39;</span>, <span class="kw">hat</span>(theta))));<span class="kw">box</span>()


<span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">mean</span>(mouse.c), <span class="dt">col=</span><span class="st">&#39;red&#39;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>mouse.ci$normal[<span class="dv">2</span>:<span class="dv">3</span>],<span class="dt">col=</span><span class="st">&#39;green&#39;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>mouse.ci$basic[<span class="dv">4</span>:<span class="dv">5</span>],<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>mouse.ci$student[<span class="dv">4</span>:<span class="dv">5</span>],<span class="dt">col=</span><span class="st">&#39;green&#39;</span>,<span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>mouse.ci$percent[<span class="dv">4</span>:<span class="dv">5</span>],<span class="dt">col=</span><span class="st">&#39;blue&#39;</span>,<span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>mouse.ci$bca[<span class="dv">4</span>:<span class="dv">5</span>],<span class="dt">col=</span><span class="st">&#39;orange&#39;</span>)

<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>,<span class="kw">c</span>(<span class="st">&#39;Est.&#39;</span>,<span class="st">&#39;Normal&#39;</span>,<span class="st">&#39;Basic&#39;</span>,<span class="st">&#39;Student&#39;</span>,<span class="st">&#39;Percent&#39;</span>,<span class="st">&#39;BCa&#39;</span>),
<span class="dt">col=</span><span class="kw">c</span>(<span class="st">&#39;red&#39;</span>,<span class="st">&#39;green&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;green&#39;</span>,<span class="st">&#39;blue&#39;</span>,<span class="st">&#39;orange&#39;</span>),<span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-18-1.png" alt="" /><!-- --></p>
</div>
<div id="example-2-non-parametric-bootstrap-for-causal-effect-estimates-in-marginal-structural-models" class="section level4">
<h4><span class="header-section-number">3.2.3.2</span> Example 2: Non-parametric Bootstrap for Causal Effect Estimates in Marginal Structural Models</h4>
<p><em>Labour Training Evaluation Data</em>: This data frame from the <code>DAAG</code> package <span class="citation">(Maindonald and Braun <a href="placeholder.html#ref-R-DAAG">2015</a>)</span> contains 445 rows and 10 columns. These data are from an investigation of the effect of training on changes, between 1974-1975 and 1978, in the earnings of individuals who had experienced employment difficulties. Data are for the male experimental control and treatment groups. The goal of this study was to determine if a job training intervention led to increased earnings. The training program was created to encourage people to get to work and to take better jobs. Here are the data:</p>
<p><div id="htmlwidget-6518" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-6518">{"x":{"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190","191","192","193","194","195","196","197","198","199","200","201","202","203","204","205","206","207","208","209","210","211","212","213","214","215","216","217","218","219","220","221","222","223","224","225","226","227","228","229","230","231","232","233","234","235","236","237","238","239","240","241","242","243","244","245","246","247","248","249","250","251","252","253","254","255","256","257","258","259","260","1100","261","310","410","510","610","710","810","910","1010","1110","1210","1310","1410","1510","1610","1710","1810","1910","2010","2110","2210","2310","2410","2510","262","271","281","291","301","311","321","331","341","351","361","371","381","391","401","411","421","431","441","451","461","471","481","491","501","511","521","531","541","551","561","571","581","591","601","611","621","631","641","651","661","671","681","691","701","711","721","731","741","751","761","771","781","791","801","811","821","831","841","851","861","871","881","891","901","911","921","931","941","951","961","971","981","991","1001","1011","1021","1031","1041","1051","1061","1071","1081","1091","1101","1111","1121","1131","1141","1151","1161","1171","1181","1191","1201","1211","1221","1231","1241","1251","1261","1271","1281","1291","1301","1311","1321","1331","1341","1351","1361","1371","1381","1391","1401","1411","1421","1431","1441","1451","1461","1471","1481","1491","1501","1511","1521","1531","1541","1551","1561","1571","1581","1591","1601","1611","1621","1631","1641","1651","1661","1671","1681","1691","1701","1711","1721","1731","1741","1751","1761","1771","1781","1791","1801","1811","1821","1831","1841","1851"],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[23,26,22,18,45,18,24,34,24,36,21,28,27,19,20,34,24,22,25,39,19,44,27,25,31,34,21,33,18,26,31,35,20,25,25,35,20,25,27,20,26,38,34,19,32,20,23,38,24,23,20,21,25,22,23,24,29,24,22,28,18,26,25,24,26,36,22,25,27,29,24,22,24,29,25,30,22,55,20,34,22,32,31,18,50,25,23,38,25,42,39,34,24,32,27,26,44,25,25,28,32,22,19,31,23,33,27,29,23,25,25,24,28,26,30,25,29,25,28,23,54,33,20,45,39,26,23,27,33,25,23,18,17,19,18,18,17,19,19,18,18,18,17,18,18,19,18,17,17,19,17,18,18,17,19,19,17,20,17,17,17,19,19,20,18,18,17,19,17,17,18,21,18,19,24,28,25,21,39,36,24,17,18,18,28,27,31,22,31,26,18,23,20,19,18,17,27,27,28,28,21,17,26,29,17,22,24,20,18,24,21,30,31,17,19,23,22,29,22,29,19,17,18,19,20,33,36,25,19,23,17,43,26,27,19,28,28,26,31,23,20,28,39,21,22,20,21,23,29,28,30,25,28,22,44,21,28,29,25,22,37,22,30,27,33,22,23,32,22,33,19,21,18,27,17,19,27,23,40,26,23,41,38,24,18,29,25,27,17,24,17,48,25,20,25,42,25,23,46,24,21,19,17,18,20,25,17,17,25,23,28,31,18,25,30,17,37,41,42,22,17,29,35,27,29,28,27,23,45,29,27,46,18,25,28,25,22,21,40,22,25,18,38,27,27,38,23,26,21,25,31,17,25,21,44,25,18,42,25,31,24,26,25,18,19,43,27,17,30,26,20,17,20,18,27,21,27,20,19,23,29,18,19,27,18,27,22,23,23,20,17,28,26,20,24,31,23,18,29,26,24,25,24,46,31,19,19,27,26,20,28,24,19,23,42,25,18,21,27,21,22,31,24,29,29,19,19,31,22,21,17,26,20,19,26,28,22,33,22,29,33,25,35,35,33],[10,12,9,9,11,9,8,11,4,10,14,9,7,11,8,12,10,8,11,9,9,9,8,8,10,10,7,12,10,12,12,10,12,11,10,11,10,9,10,11,11,8,10,12,8,9,10,10,11,11,7,11,10,11,11,12,11,11,9,11,10,10,10,10,5,10,11,12,11,8,12,10,7,12,11,12,8,3,10,11,12,12,10,9,10,11,10,10,10,10,12,13,7,11,13,10,11,11,12,12,10,10,9,10,11,11,10,11,10,9,10,10,8,6,14,10,11,12,13,11,11,5,8,9,6,12,10,12,9,10,8,8,8,9,8,11,11,10,10,9,9,10,10,7,11,10,9,10,10,11,8,10,9,8,6,10,11,9,9,10,9,11,10,9,9,11,10,11,10,9,10,9,10,11,9,11,11,7,11,12,12,11,10,10,10,13,12,9,10,10,9,11,12,10,11,10,12,11,12,11,10,10,11,9,10,11,11,12,12,11,9,8,11,10,9,11,12,12,10,13,11,9,10,12,6,11,11,11,11,8,11,10,11,11,11,11,12,8,12,11,12,10,12,8,11,11,11,12,9,9,11,10,11,10,9,9,11,9,9,10,11,9,12,11,8,9,12,11,16,12,9,13,8,10,7,10,13,10,12,12,11,14,9,11,10,11,11,10,10,11,10,4,11,12,12,14,5,12,8,10,12,9,8,8,11,11,8,9,5,12,8,11,11,12,11,10,9,4,14,11,8,8,10,11,4,9,11,7,5,13,9,13,6,12,15,11,12,9,11,11,12,12,12,13,8,11,8,11,12,8,11,10,11,12,11,12,9,12,10,9,10,10,11,11,11,9,13,9,11,10,9,9,12,11,12,12,12,12,10,12,14,10,9,13,11,9,12,10,12,11,9,11,11,11,11,9,8,10,12,11,9,12,10,8,12,11,8,11,11,10,10,12,8,12,9,13,9,12,10,8,9,4,10,10,12,10,11,9,10,9,10,12,9,10,10,11,12,11,12,10,12,14,9,8,11],[1,0,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,1,1,0,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,0,1,0,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,1,0,1,0,0,1,1,1,1,1],[0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,1,1,0,1,0,1,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1,0,1,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0,1,1,0,0,0,0,0,0,1,1,1,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,1,0,1,0,0,0,0,0,1,0,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,1,0,1,0,0,1,0,0,0,0,1,0,0,0,1,1,1,1,1],[1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,0,1,1,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,0,1,1,1,0,1,0,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,0,0,1,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,0,1,0,1,1,1,1,0,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,0,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,0,1,0,1,1,1,0,0,0,0,1,1,1,1,0,1,1,1,1,0,1,0,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,1,0,1,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,1,1,1,1,0,1,0,1,0,1,0,1,1,1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1,0,1,0,1,0,0,1,1,1],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,591.4991,1563.249,1626.623,2788.498,3472.948,5281.245,33799.95,0,0,0,989.2678,960.4268,0,1471.293,5214.306,0,0,0,6140.367,0,6382.309,0,0,1064.699,0,0,3065.194,0,2431.949,6661.063,4905.119,4699.963,0,1203.609,7914.131,0,557.6988,0,2669.725,2988.412,0,17711.88,1442.681,8409.627,0,4380.017,22859.44,0,718.2492,721.3406,0,1716.509,8417,6006.879,10523.83,5443.734,15209.99,3504.014,7724.283,4080.73,2502.868,0,0,6337.492,8593.163,10585.13,1126.29,0,7617.362,7182.492,8293.345,19785.32,39570.68,8810.067,8009.164,2992.534,5721.696,9268.943,10222.41,0,13519.97,824.3889,27864.36,12260.78,31886.43,17491.45,9594.308,24731.62,25720.92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2027.999,6083.994,445.1704,989.2678,858.2543,3670.872,3670.872,2143.413,0,0,5506.308,0,0,0,9381.566,3678.231,0,5605.852,0,9385.74,3637.498,1716.509,0,0,16318.62,824.3886,0,0,2143.411,10881.94,0,9154.7,14426.79,4250.402,3165.658,0,2305.026,0,2206.94,0,5005.731,0,13765.75,2636.353,6269.341,0,12362.93,0,6473.683,1001.146,989.2678,2192.877,8517.589,11703.2,0,9748.387,0,5424.485,10717.03,1468.348,6416.47,1291.468,8408.762,12260.78,4121.949,25929.68,1929.029,492.2305,0,6759.994,0,20279.95,35040.07,13602.43,13732.07,14660.71],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83.68964,142.3973,159.8847,165.2077,240.1067,273.5525,367.8234,474.5018,494.643,506.4076,520.4463,558.7734,559.596,580.7901,591.8151,604.1539,645.2723,664.569,752.3901,766.2986,803.343,863.4795,1162.362,1168.902,1174.991,1203.824,1239.628,1321.66,1327.993,1371.473,1405.512,1468.383,1577.167,1706.657,1726.445,1734.559,1778.089,1896.023,2003.68,2080.209,2174.955,2265.579,2445.589,2595.267,2682.125,2814.195,2850.61,2899.82,3063.878,3072.726,3285.68,3403.056,3796.029,4128.443,4184.732,4491.884,4503.064,5393.895,5551.456,5562.598,5613.909,5716.407,6004.728,6449.48,6608.137,6608.304,6974.484,7666.875,8920.471,8960.684,9160.693,9210.447,9311.938,9319.444,10033.91,10598.67,10857.24,12357.22,13371.25,16341.16,16946.63,23031.98,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,74.34345,165.2077,214.5636,334.0493,334.0494,357.9499,377.5686,385.2741,501.0741,679.6734,798.9079,798.9079,853.7225,919.5579,934.4454,936.1773,936.4386,1117.439,1220.836,1253.439,1284.079,1392.853,1484.994,1666.113,1698.607,1713.15,1784.274,1817.284,2226.266,2288.675,2409.274,2421.947,2594.723,2611.218,2615.276,2657.057,2666.274,2754.646,2777.355,2836.506,2842.764,2937.264,3039.96,3058.531,3090.732,3287.375,3332.409,3550.075,3695.897,3836.986,4023.211,4078.152,4398.95,4878.937,5324.109,5463.803,5517.841,5588.664,5749.331,5793.852,5794.831,5875.049,6056.754,6788.958,6871.856,7055.702,7867.916,8455.504,8853.674,10941.35,11536.57,13830.64,17976.15,25142.24],[0,12383.68,0,10740.08,11796.47,9227.052,10569.27,6040.335,3880.833,0,5775.062,0,0,0,0,2113.722,7618.639,9920.945,4196.375,0,16658.25,9722.003,3783.66,3515.929,17014.59,0,0,5970.257,1859.167,6191.943,7284.394,445.8309,0,0,7367.04,0,2015.503,15791.13,1135.47,6378.72,7176.187,0,7952.54,0,7152.132,8329.823,0,12429.91,0,5088.76,4374.04,1553.291,0,1698.304,0,11294.63,0,14626.39,12898.38,5767.133,6527.919,3931.238,20942.24,0,0,14690.35,0,3418.097,11197.34,0,0,0,1455.69,1890.937,4485.616,13613.35,1390.509,5843.796,8598.522,2920.199,0,6735.32,0,0,0,44.75546,0,0,3701.812,6930.336,3795.799,5193.247,2193.528,11120.53,7609.518,2169.027,0,1264.232,0,0,0,0,5712.643,0,0,0,1184.882,10225.88,0,4715.371,289.7899,0,8190.421,4813.05,7344.678,0,0,0,0,4350.907,7812.522,0,3644.655,4844.803,0,0,0,14792.9,0,0,3746.701,1568.15,7010.444,3811.683,10798.56,4657.273,8551.533,4309.878,5286.396,12486.17,10877.35,202.2847,2657.705,4132.577,11303.14,0,0,0,2189.426,0,10210.99,11048.08,0,8993.865,5071.801,3194.01,0,5193.089,0,275.5661,3590.702,0,12797.67,2035.914,2389.679,0,8469.275,0,1143.387,5114.814,781.2243,3343.224,9602.439,0,16461.57,6771.622,0,11011.57,0,0,0,4251.127,2891.668,5514.365,4858.895,4812.576,0,604.1987,14527.88,0,7300.498,0,4159.919,0,5497.591,0,0,0,16477.02,0,39483.53,11306.27,6672.021,9378.653,5088.986,2639.29,9495.902,20893.11,0,10361.69,1740.199,0,0,6354.194,7171,5573.547,439.6881,16969.95,5344.021,2725.322,9772.283,0,0,1720.907,0,18859.89,1324.542,284.6584,11195.93,0,0,7565.273,0,0,0,4974.586,12780.02,3523.578,0,10274.84,4779.72,16988.18,499.2572,3083.581,3708.719,7659.218,20857.84,7078.178,0,1239.844,3982.801,0,0,7094.92,12359.31,0,0,16900.3,7343.964,5448.801,9930.046,3595.894,24909.45,7506.146,289.7899,4056.494,0,8472.158,2164.022,12418.07,8173.908,17094.64,0,18739.93,3023.879,3228.503,14581.86,7693.4,10804.32,10747.35,0,5149.501,6408.95,1991.4,11163.17,9642.999,9897.049,11142.87,16218.04,995.7002,0,6551.592,1574.424,0,3191.753,20505.93,6181.88,5911.551,3094.156,0,1254.582,13188.83,8061.485,2787.96,3972.54,0,0,0,12187.41,4843.176,0,8087.487,0,2348.973,590.7818,0,1067.506,7284.986,13167.52,1048.432,0,1923.938,4666.236,549.2984,762.9146,10694.29,0,0,8546.715,7479.656,0,647.2046,0,11965.81,9598.541,18783.35,18678.08,0,23005.6,6456.697,0,2321.107,4941.849,0,0,0,3881.284,17230.96,8048.603,0,14509.93,0,0,9983.784,0,5587.503,4482.845,2456.153,0,26817.6,0,9265.788,485.2298,4814.627,7458.105,0,34099.28,1953.268,0,0,8881.665,6210.67,0,929.8839,0,12558.02,22163.25,1652.637,8124.715,671.3318,17814.98,9737.154,17685.18,0,4321.705,1773.423,0,11233.26,559.4432,1085.44,5445.2,60307.93,1460.36,6943.342,4032.708,10363.27,4232.309,11141.39,0,13385.86,4849.559,0,1660.508,0,2484.549,4146.603,9970.681,0,26372.28,5615.189,3196.571,6167.681,7535.942,8484.239,1294.409,0,5010.342,9371.037,0,4279.613,3462.564,7382.549,0,0,10976.51,13829.62,6788.463,9558.501,13228.28,743.6666,5522.788,1424.944,1358.643,0,672.8773,0,10092.83,6281.433,12590.71,5112.014,15952.6,36646.95,12803.97,3786.628,4181.942]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> \u003c/th>\n      <th>trt\u003c/th>\n      <th>age\u003c/th>\n      <th>educ\u003c/th>\n      <th>black\u003c/th>\n      <th>hisp\u003c/th>\n      <th>marr\u003c/th>\n      <th>nodeg\u003c/th>\n      <th>re74\u003c/th>\n      <th>re75\u003c/th>\n      <th>re78\u003c/th>\n    \u003c/tr>\n  \u003c/thead>\n\u003c/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7,8,9,10]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false},"callback":null,"filter":"none","selection":"multiple"},"evals":[],"jsHooks":[]}</script></p>
<p>We are interested in evaluating the effect of a binary treatment, participation in the training program or not, on the continuous outcome of real income in 1978. In this study, treatment is not randomized, therefore direct comparison of the 1978 earnings between treated and untreated will lead to a biased estimate of the effect of the training program. The covariates were not balanced between groups.</p>
<p>The propensity score (PS) for an individual, defined as the conditional probability of being treated given the individual’s covariates, can be used to balance the covariates in the two groups, and thus reduce this bias. Once estimated, the propensity score can be used to reduce bias through weighted regression <span class="citation">(dAgostino <a href="placeholder.html#ref-d1998tutorial">1998</a>)</span>. Propensity scores provide a summary measure to control for multiple confounders simultaneously. Inverse probability of treatment weighting (IPTW) using PS has several advanages over multiple linear regression adjustment for several reasons. It is simpler to determine whether the propensity score (PS) model has been adequately specified <span class="citation">(Austin <a href="placeholder.html#ref-austin2011introduction">2011</a>)</span> by checking if the distribution of baseline measured covariates is similar in both groups conditional on the PS. Regression diagnostics are complicated when several predictors and their interactions are put in the model. Furthermore, for regression based methods, goodness of fit measures provide no test of whether the outcome model has been correctly specified, and the degree to which the fitted model has eliminated systematic difference between control and treatment groups <span class="citation">(Austin <a href="placeholder.html#ref-austin2011introduction">2011</a>)</span>. The PS is estimated without reference to the outcome whereas this is not the case in regression methods, which can lead to <em>hypothesis generation</em>, i.e. continually fit different models until a desirable result is achieved. Finally, IPTW methods can fit very complicated PS models with interactions and higher order terms, even non-parametrically, without concern of over-fitting since the goal is to obtain the best estimated probability of treatment assignment.</p>
<p>Let <span class="math inline">\(Z\)</span> denote the indicator for receiving treatment, <span class="math inline">\(\mathbf{X}\)</span> a vector of pre-exposure covariates, and <span class="math inline">\(Y\)</span> the observed outcome. To estimate the average causal treatment effect we use the potential outcomes framework <span class="citation">(Rosenbaum and Rubin <a href="placeholder.html#ref-rosenbaum1983central">1983</a>)</span>. Let <span class="math inline">\(Y_0\)</span> and <span class="math inline">\(Y_1\)</span> denote the outcome a subject would have if they didn’t and did received the training program, respectively. The causal effect of the training program on earnings may be defined as for instance the difference <span class="math inline">\(Y_1-Y_0\)</span>. Since only one of the potential outcomes can be observed, in practice this difference is replaced by the average causal effect <span class="math inline">\(\Delta=E(Y_1)-E(Y_0)\)</span>. If treatment assignment is completely randomized, i.e., <span class="math inline">\((Y_0,Y_1)\perp Z\)</span> then <span class="math inline">\(\bar{Y}_1 - \bar{Y}_0\)</span> is an unbiased estimator for <span class="math inline">\(\Delta\)</span>. However in this study this assumption is violated because the value of <span class="math inline">\(Z\)</span> has not been determined through complete randomization. It may be then that <span class="math inline">\((Y_0,Y_1)\)</span> and <span class="math inline">\(Z\)</span> have common determinants, meaning that the treatment is informative of the pair of potential outcomes. If we assume <span class="math inline">\(\mathbf{X}\)</span> contains all confounders then among subjects sharing the same <span class="math inline">\(\mathbf{X}\)</span> there will be no association between exposure and potential outcomes, i.e., <span class="math inline">\((Y_0,Y_1)\perp Z|\mathbf{X}\)</span>.</p>
<p>The propensity score is defined as <span class="math inline">\(e(\mathbf{X},\mathbf{\beta})= P(Z=1|\mathbf{X})\)</span>. We estimate this probability using logistic regression where <span class="math inline">\(\mathbf{X}\)</span> contains age, age<span class="math inline">\(^2\)</span>, years of education and its square term, indicators for no degree, black, hispanic, actual 1974-1975 earnings and their square terms. Then we can estimate the causal parameter <span class="math inline">\(\Delta\)</span> using a weighted linear regression; regressing 1978 earnings on treatment with weights corresponding to <span class="math inline">\(e(\mathbf{X},\mathbf{\widehat{\beta}})^{-1}\)</span> for treated and <span class="math inline">\(\left(1-e(\mathbf{X},\mathbf{\widehat{\beta}})\right)^{-1}\)</span> for untreated individuals.</p>
<p>To determine the effect of treatment on change in earnings from 1975 to 1978, we will fit an IPTW regression model using 1975 earnings as the response. The covariates used for calculating the PS will be similar to the previous model except it will not have 1975 earnings in it. The desired effect estimate will then be the difference of the causal paramters estimated from each model, i.e., <span class="math inline">\(\widehat{\Delta}_{\left(1978\right)} - \widehat{\Delta}_{\left(1975\right)}\)</span>. We will repeat this calculation on <span class="math inline">\(B=4000\)</span> (stratified on treatment) bootstrap samples to get an estimate of the standard error of this statistic.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(DAAG) <span class="co"># for the data</span></code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;lattice&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:boot&#39;:
## 
##     melanoma</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(boot) <span class="co"># for bootstrap confidence intervals</span>

<span class="co"># function that fits the IPTW using PS for both models</span>
<span class="co"># and returns the difference of the causal parameters</span>
<span class="co"># this will be passed to the boot package</span>
did &lt;-<span class="st"> </span>function(data, indices){
    
    d &lt;-<span class="st"> </span>data[indices,]
   
    <span class="co"># PS for 1978</span>
    ps1 &lt;-<span class="st"> </span><span class="kw">glm</span>(trt ~<span class="st"> </span>age +<span class="st"> </span><span class="kw">I</span>(age^<span class="dv">2</span>) +<span class="st"> </span>educ +<span class="st"> </span><span class="kw">I</span>(educ^<span class="dv">2</span>) +<span class="st"> </span>black +<span class="st"> </span>hisp +<span class="st"> </span>
<span class="st">                           </span>re74 +<span class="st"> </span><span class="kw">I</span>(re74^<span class="dv">2</span>) +<span class="st"> </span>re75 +<span class="st"> </span><span class="kw">I</span>(re75^<span class="dv">2</span>) +<span class="st"> </span>nodeg,
                       <span class="dt">data=</span>d, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)
    
    <span class="co"># weights</span>
    w1 &lt;-<span class="st"> </span><span class="dv">1</span>/<span class="kw">ifelse</span>(d$trt==<span class="dv">1</span>,<span class="kw">predict</span>(ps1,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>),
                   <span class="dv">1</span>-<span class="kw">predict</span>(ps1,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>))
    
    <span class="co"># Marginal structural model</span>
    msm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(re78 ~<span class="st"> </span>trt, <span class="dt">weights=</span>w1, <span class="dt">data=</span>d)
    
    <span class="co"># PS for 1975 (same as above but doesnt have 1975 earnings)</span>
    ps2 &lt;-<span class="st"> </span><span class="kw">glm</span>(trt ~<span class="st"> </span>age +<span class="st"> </span><span class="kw">I</span>(age^<span class="dv">2</span>) +<span class="st"> </span>educ +<span class="st"> </span><span class="kw">I</span>(educ^<span class="dv">2</span>) +<span class="st"> </span>black +<span class="st"> </span>hisp +<span class="st"> </span>
<span class="st">                           </span>re74 +<span class="st"> </span><span class="kw">I</span>(re74^<span class="dv">2</span>) +<span class="st"> </span>nodeg,
                       <span class="dt">data=</span>d, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)
    
    w2 &lt;-<span class="st"> </span><span class="dv">1</span>/<span class="kw">ifelse</span>(d$trt==<span class="dv">1</span>,<span class="kw">predict</span>(ps2,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>),
                   <span class="dv">1</span>-<span class="kw">predict</span>(ps2,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>))
    
    msm2 &lt;-<span class="st"> </span><span class="kw">lm</span>(re75 ~<span class="st"> </span>trt, <span class="dt">weights=</span>w2, <span class="dt">data=</span>d)
    
    <span class="co"># return the paramter of interest</span>
    <span class="kw">return</span>(<span class="kw">coef</span>(msm1)[<span class="dv">2</span>]-<span class="kw">coef</span>(msm2)[<span class="dv">2</span>])
}


results &lt;-<span class="st"> </span><span class="kw">boot</span>(<span class="dt">data =</span> nsw74demo, 
                <span class="dt">statistic =</span> did, <span class="dt">R =</span> <span class="dv">1000</span>, 
                <span class="dt">strata =</span> <span class="kw">factor</span>(nsw74demo$trt))</code></pre></div>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred

## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results</code></pre></div>
<pre><code>## 
## STRATIFIED BOOTSTRAP
## 
## 
## Call:
## boot(data = nsw74demo, statistic = did, R = 1000, strata = factor(nsw74demo$trt))
## 
## 
## Bootstrap Statistics :
##     original   bias    std. error
## t1* 1322.253 4.992589    735.5867</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(results)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-20-1.png" alt="" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boot.ci</span>(results, <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;norm&quot;</span>,<span class="st">&quot;basic&quot;</span>, <span class="st">&quot;perc&quot;</span>) )</code></pre></div>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = results, type = c(&quot;norm&quot;, &quot;basic&quot;, &quot;perc&quot;))
## 
## Intervals : 
## Level      Normal              Basic              Percentile     
## 95%   (-124, 2759 )   (-191, 2743 )   ( -98, 2835 )  
## Calculations and Intervals on Original Scale</code></pre>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="vectorization-apply-and-for-loops.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="placeholder.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/sahirbhatnagar/biosR/edit/master/02-simulations.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

[
["index.html", "Biostatistics in R Chapter 1 Prerequisites 1.1 Install R and RStudio 1.2 R Packages 1.3 Background Reading", " Biostatistics in R Sahir Rai Bhatnagar 2016-04-14   Chapter 1 Prerequisites  1.1 Install R and RStudio All examples in this book are run in an R environment. You also need a recent version of RStudio, which is a software application that facilitates how you interact with R. It is developed by data enthusiasts who consider statistics to be more than just simulations, formulas and proofs. RStudio emphasizes the following:  Version control: Why I should use version control especially for the solo data analyst. Reproducible research: seamless integration with RMarkdown for creating dynamic documents and presentations Creating R Packages: seamless integration with the devtools package for creating software that implements your statistical method or analysis.    1.2 R Packages The following packages will be called upon at some point, so please install them before getting started with the tutorials. Enter the following command in R: install.packages(c(&quot;data.table&quot;, &quot;rmarkdown&quot;, &quot;dplyr&quot;, &quot;purrr&quot;, &quot;tidyr&quot;, &quot;ggplot2&quot;))   1.3 Background Reading The greatest thing about R is that there are so many people out there willing to help you. R users are constantly writing tutorials and creating packages to make your analysis tasks easier. Here is a very targeted list that I suggest reading prior to starting the tutorials  Writing Functions For loops    "],
["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 4. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, 0.1, 0.1)) plot(pressure, type = &quot;b&quot;, pch = 19)    Figure 2.1: Here is a nice figure!   Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable(   head(iris, 20), caption = &#39;Here is a nice table!&#39;,   booktabs = TRUE )  Table 2.1: Here is a nice table!   Sepal.Length Sepal.Width Petal.Length Petal.Width Species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa   5.4 3.9 1.7 0.4 setosa   4.6 3.4 1.4 0.3 setosa   5.0 3.4 1.5 0.2 setosa   4.4 2.9 1.4 0.2 setosa   4.9 3.1 1.5 0.1 setosa   5.4 3.7 1.5 0.2 setosa   4.8 3.4 1.6 0.2 setosa   4.8 3.0 1.4 0.1 setosa   4.3 3.0 1.1 0.1 setosa   5.8 4.0 1.2 0.2 setosa   5.7 4.4 1.5 0.4 setosa   5.4 3.9 1.3 0.4 setosa   5.1 3.5 1.4 0.3 setosa   5.7 3.8 1.7 0.3 setosa   5.1 3.8 1.5 0.3 setosa    You can write citations, too. For example, we are using the bookdown package (Xie 2016) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). ddd aaa (Davison and Hinkley 1997) library(boot)  mouse.c &lt;- scan(&quot;http://www.rohan.sdsu.edu/~babailey/stat672/mouse.c.data&quot;) mouse.t &lt;- scan(&quot;http://www.rohan.sdsu.edu/~babailey/stat672/mouse.t.data&quot;)   y &lt;- mouse.c sd(y) ## [1] 42.41691 n.c &lt;- length(mouse.c)  B &lt;- 1e+05  thetahat.c &lt;- mean(mouse.c) sehat.c &lt;- sd(mouse.c) * sqrt((n.c - 1)/n.c^2)  theta.boot &lt;- rep(0, B)  Zb &lt;- rep(0, B) Zbt &lt;- rep(0, B) for (b in 1:B) {          yboot &lt;- sample(mouse.c, size = n.c, rep = T)     thetahat.boot &lt;- mean(yboot)     sehat.boot &lt;- sd(yboot) * sqrt((n.c - 1)/n.c^2)          Zb[b] &lt;- (thetahat.boot - thetahat.c)/sehat.c          Zbt[b] &lt;- (thetahat.boot - thetahat.c)/sehat.boot          theta.boot[b] &lt;- thetahat.boot      } hist(theta.boot, xlab = expression(theta), col = &quot;gray&quot;, main = expression(paste(&quot;Bootstrap resamples of &quot;,      hat(theta)))) box() abline(v = thetahat.c, col = &quot;red&quot;, lwd = 2)  abline(v = quantile(theta.boot, prob = c(0.025, 0.975)), col = &quot;red&quot;, lty = 2,      lwd = 2)  alpha &lt;- 0.05 qs &lt;- quantile(Zb, prob = c(1 - alpha/2, alpha/2)) qst &lt;- quantile(Zbt, prob = c(1 - alpha/2, alpha/2)) abline(v = thetahat.c - qst * sehat.c, col = &quot;green&quot;, lty = 2, lwd = 2) abline(v = thetahat.c - qs * sehat.c, col = &quot;blue&quot;, lty = 2, lwd = 2)   "],
["simulations.html", "Chapter 3 Simulations 3.1 What is a simulation study? 3.2 Why conduct a simulation study?", " Chapter 3 Simulations In this chapter you’ll learn how to conduct a simulation study. The word simulation gets thrown around alot as a trivial concept, though I have found that this term is often either misused by epidemiologists or abused by statisticians. A source of this confusion arises from the fact that it is not well defined. This is not by accident. A simulation study has so many moving parts that it would be impossible to characterize in a single word. However, there are some common underlying themes behind simulation studies. For this reason, the main focus here will be on creating a general roadmap for conducting these types of analyses, that can be applied to your specific setting.  3.1 What is a simulation study? Here are some results from a Google Search:  A numerical technique for conducting experiments on the computer (Davidian 2005) Simulations provide a powerful technique for answering a broad set of methodological and theoretical questions and provide a flexible framework to answer specific questions relevant to one’s own research(Hallgren 2013)  I prefer the second definition because it speaks to the generality of simulations. I see simulations in the following way1:  {\"x\":{\"diagram\":\"\\ngraph LR\\nA((Input 1))-->B{Procedure}\\nD((Input 2))-->B{Procedure}\\nE((Input 3))-->B{Procedure}\\nB-->C[Output 1]\\nB-->F[Output 1]\\nB-->G[Output 1]\\n\"},\"evals\":[],\"jsHooks\":[]} There are three crucial components to any simulation study:  Procedure - something that doesn’t change throughout the simulation study Input: several values of the same quantity that are passed to the procedure. Output: result from the procedure being applied to the inputs. Should be equal in length to the number of outputs. The following toy example illustrates this point:  f_sample_median &lt;- function(true_mean) {     x &lt;- rnorm(20, mean = true_mean, sd = 1)     median(x) }  (means &lt;- c(1, 2, 3)) ## [1] 1 2 3 (sample_medians &lt;- sapply(means, f_sample_median)) ## [1] 1.119985 1.860057 2.964291 So here, f_sample_median is the procedure that generates 20 random numbers from a normal distribution with standard deviation 1 and a user specified mean, and outputs the sample median. means is the input vector of user specified means, and sample_medians is the output:  {\"x\":{\"diagram\":\"\\ngraph LR\\nA((1))-->B{f_sample_median}\\nD((2))-->B\\nE((3))-->B\\nB-->C[1.12]\\nB-->F[1.86]\\nB-->G[2.96]\\n\"},\"evals\":[],\"jsHooks\":[]} Using this very general definition of the word simulation, I see the following analysis techinques as a type of simulation.  {\"x\":{\"diagram\":\"\\ngraph TB\\nsq[Simulation] --> ci[Bootstrap]\\nsq --> A[Cross Validation]\\nsq --> B[Sensitivity Analysis]\\nsq --> C[Permutations]\\nclassDef green fill:#9f6,stroke:#333,stroke-width:2px;\\nclassDef orange fill:#f96,stroke:#333,stroke-width:4px;\\nclass sq green\\n\"},\"evals\":[],\"jsHooks\":[]} Boostrap, Cross Validation, Sensitivity analysis and Permutations are all similar in that they have multiple inputs with an equal number of outputs, with a fixed procedure. What differentiates them is the context in which they can be applied. The technique you choose depends entirely on the question you’re trying to answer.   3.2 Why conduct a simulation study? The most common applications of simulation studies are the following  3.2.1 Understanding the behaviour of a statistical quantity  3.2.1.1 Example 1: The Central Limit Theorem The Central Limit Theorem is one of the most famous theorems in statistics. This theorem basically states that the sum or mean of independent random variables (with finite mean and variance) will converge to a normal distribution, regardless of the distribution of the random variables. The following figure clearly illustrates this point (Joseph 2010)  In this example, the statistical quantity of interest is the sum of the random variables. We want to verify that the sum of the time it takes to get to Purvis hall follows a normal distribution. Of course the CLT can be proven mathematically, but we can also simulate random numbers from different distributions in R to numerically verify this result: # number of random numbers to generate from each distribution n &lt;- 10000  # true parameters of each distribution mean.walk &lt;- 4 var.walk &lt;- 1 mean.bus &lt;- (4 + 16)/2 var.bus &lt;- (16 - 4)^2/12 mean.ride &lt;- 8 var.ride &lt;- 8 mean.climb &lt;- 6 * 0.5 var.climb &lt;- 6 * 0.5^2 mean.fall &lt;- 1/4 var.fall &lt;- 1/4^2  # generate random samples from each distribution walk &lt;- rnorm(n, mean.walk, var.walk) bus &lt;- runif(n, 4, 16) ride &lt;- rpois(n, mean.ride) climb &lt;- rgamma(n, shape = 6, scale = 0.5) fall &lt;- rexp(n, rate = 1/mean.fall)  # true mean and variance of sum mean.sum &lt;- mean.walk + mean.bus + mean.ride + mean.climb + mean.fall var.sum &lt;- var.walk + var.bus + var.ride + var.climb + var.fall  # create a data frame of the data and calculate the sum for each sample DT &lt;- data.frame(walk, bus, ride, climb, fall) DT$sum &lt;- apply(DT, 1, sum)  # plot each histogram and superimpose theoretical distribution to empirical # one par(mfrow = c(2, 3)) hist(walk, main = &quot;Normal(mean=4,sd=1)&quot;, freq = FALSE) hist(bus, main = &quot;Uniform(a=4,b=16)&quot;, freq = FALSE) hist(ride, main = &quot;Poisson(lambda=8)&quot;, freq = FALSE) hist(climb, main = &quot;Gamma(shape=6, scale=0.5)&quot;, freq = FALSE) hist(fall, main = &quot;Exponential(rate=4)&quot;, freq = FALSE) hist(DT$sum, xlab = &quot;Total time&quot;, main = paste(&quot;Distribution of Sum, n = &quot;,      n), freq = FALSE) curve(dnorm(x, mean = mean.sum, sd = sqrt(var.sum)), 0, 50, add = TRUE, lwd = 2,      col = &quot;red&quot;)    3.2.1.2 Example 2: Power Calculation When performing Student’s t-test to compare difference in means between two group, it is a useful exercise to determine the effect of unequal sample sizes in the comparison groups on power. Large imbalances generally will not have adequate statistical power to detect even large effect sizes associated with a factor, leading to a high Type II error rate as shown in the figure below:  To jusity this reasoning I performed a power analysis for different group sizes. I considered the following group sizes:  n1 = 28, n2 = 1406: n1 represents 2% of the entire sample size of 1434 n1 = 144, n2 = 1290: n1 represents 10% of the entire sample size of 1434 n1 = 287, n2 = 1147: n1 represents 20% of the entire sample size of 1434 n1 = 430, n2 = 1004: n1 represents 30% of the entire sample size of 1434 n1 = 574, n2 = 860: n1 represents 40% of the entire sample size of 1434 n1 = 717, n2 = 717: equal size groups (this is optimal because it leads to the highest power for a given effect size)  In the figure above we plotted the power curves for the \\(t\\)-test, as a function of the effect size, assuming a Type I error rate of 5%. Here is the code used to produce the above plot library(pwr)  # for power calcs library(dplyr)  # for data manipulation library(tidyr)  # for data manipulation library(ggplot2)  # for plotting power curves  # Generate power calculations ptab &lt;- cbind(NULL, NULL)  for (i in seq(0, 1, length.out = 200)) {     pwrt1 &lt;- pwr.t2n.test(n1 = 28, n2 = 1406, sig.level = 0.05, power = NULL,          d = i, alternative = &quot;two.sided&quot;)     pwrt2 &lt;- pwr.t2n.test(n1 = 144, n2 = 1290, sig.level = 0.05, power = NULL,          d = i, alternative = &quot;two.sided&quot;)     pwrt3 &lt;- pwr.t2n.test(n1 = 287, n2 = 1147, sig.level = 0.05, power = NULL,          d = i, alternative = &quot;two.sided&quot;)     pwrt4 &lt;- pwr.t2n.test(n1 = 430, n2 = 1004, sig.level = 0.05, power = NULL,          d = i, alternative = &quot;two.sided&quot;)     pwrt5 &lt;- pwr.t2n.test(n1 = 574, n2 = 860, sig.level = 0.05, power = NULL,          d = i, alternative = &quot;two.sided&quot;)     pwrt6 &lt;- pwr.t2n.test(n1 = 717, n2 = 717, sig.level = 0.05, power = NULL,          d = i, alternative = &quot;two.sided&quot;)     ptab &lt;- rbind(ptab, cbind(pwrt1$d, pwrt1$power, pwrt2$d, pwrt2$power, pwrt3$d,          pwrt3$power, pwrt4$d, pwrt4$power, pwrt5$d, pwrt5$power, pwrt6$d, pwrt6$power)) }  ptab &lt;- cbind(seq_len(nrow(ptab)), ptab)  colnames(ptab) &lt;- c(&quot;id&quot;, &quot;n1=28, n2=1406.effect size&quot;, &quot;n1=28, n2=1406.power&quot;,      &quot;n1=144, n2=1290.effect size&quot;, &quot;n1=144, n2=1290.power&quot;, &quot;n1=287, n2=1147.effect size&quot;,      &quot;n1=287, n2=1147.power&quot;, &quot;n1=430, n2=1004.effect size&quot;, &quot;n1=430, n2=1004.power&quot;,      &quot;n1=574, n2=860.effect size&quot;, &quot;n1=574, n2=860.power&quot;, &quot;n1=717, n2=717.effect size&quot;,      &quot;n1=717, n2=717.power&quot;)  # get data into right format for ggplot2 temp &lt;- ptab %&gt;% as.data.frame() %&gt;% gather(key = name, value = val, 2:13) %&gt;%      separate(col = name, into = c(&quot;group&quot;, &quot;var&quot;), sep = &quot;\\\\.&quot;) %&gt;% spread(key = var,      value = val)  # factor group temp$group &lt;- factor(temp$group, levels = c(&quot;n1=28, n2=1406&quot;, &quot;n1=144, n2=1290&quot;,      &quot;n1=287, n2=1147&quot;, &quot;n1=430, n2=1004&quot;, &quot;n1=574, n2=860&quot;, &quot;n1=717, n2=717&quot;))   # plot p &lt;- ggplot(temp, aes(x = `effect size`, y = power, color = group)) p + geom_line(size = 2) + theme_bw() + theme(legend.position = &quot;bottom&quot;, axis.text = element_text(size = 14),      axis.title = element_text(size = 14), legend.text = element_text(size = 14))    3.2.2 Model selection   3.2.3 Model assessment CV   3.2.4 Calculating measures of uncertainty Bootstrap     "],
["methods.html", "Chapter 4 Methods", " Chapter 4 Methods We describe our methods in this chapter.  "],
["applications.html", "Chapter 5 Applications 5.1 Example one 5.2 Example two", " Chapter 5 Applications Some significant applications are demonstrated in this chapter.  5.1 Example one   5.2 Example two   "],
["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book.  "],
["references.html", "Chapter 7 References", " Chapter 7 References    Davidian, Marie. 2005. Simulation Studies in Statistics. http://www4.stat.ncsu.edu/~davidian/st810a/simulation_handout.pdf.   Davison, Anthony Christopher, and David Victor Hinkley. 1997. Bootstrap Methods and Their Application. Vol. 1. Cambridge university press.   Hallgren, Kevin A. 2013. “Conducting Simulation Studies in the R Programming Environment.” Tutorials in Quantitative Methods for Psychology 9 (2). NIH Public Access: 43.   Joseph, Lawrence. 2010. Principles of Inferential Statistics in Medicine. http://www.medicine.mcgill.ca/epidemiology/Joseph/courses/EPIB-607/notes.pdf.   Sveidqvist, Knut, Mike Bostock, Chris Pettitt, Mike Daines, Andrei Kashcha, and Richard Iannone. 2016. DiagrammeR: Create Graph Diagrams and Flowcharts Using R. https://CRAN.R-project.org/package=DiagrammeR.   Xie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/.   ———. 2016. Bookdown: Authoring Books with R Markdown. https://github.com/rstudio/bookdown.       All flowcharts are created using the DiagrammeR pacakge (Sveidqvist et al. 2016)↩  "]
]
